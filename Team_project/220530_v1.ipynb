{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMEm7TZYwGwHlHKkd1s9Otl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SJin765/class_AI4dl/blob/main/Team_project/220530_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.kaggle.com/code/achinih/flower-classification-cnn-models"
      ],
      "metadata": {
        "id": "WGObhmoiKRz_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Imports"
      ],
      "metadata": {
        "id": "_fL2OUEN82tb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cfaI4BIc8xsW"
      },
      "outputs": [],
      "source": [
        "import math, re, os\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Distribution Strategy"
      ],
      "metadata": {
        "id": "LLvd71609l7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Detect TPU, return appropriate distribution strategy\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n",
        "    print('Running on TPU ', tpu.master())\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "\n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "else:\n",
        "    strategy = tf.distribute.get_strategy() \n",
        "\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
      ],
      "metadata": {
        "id": "cjHf_RnA9AJW",
        "outputId": "795d56e6-d0e5-4e7d-ad99-bd651db9b2d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "REPLICAS:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Loading the Competition Data"
      ],
      "metadata": {
        "id": "Krs4sQGF9dIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GCS에서 데이터를 받아올 경우\n",
        "# Get GCS Path\n",
        "# from kaggle_datasets import KaggleDatasets\n",
        "# GCS_DS_PATH = KaggleDatasets().get_gcs_path('tpu-getting-started')"
      ],
      "metadata": {
        "id": "sYA1jSo_9IlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 구글 드라이브에 내가 올려놓은 파일을 이용할 경우\n",
        "# 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file_path = '/content/drive/MyDrive/tpu-getting-started'"
      ],
      "metadata": {
        "id": "f7bDKnWh99_I",
        "outputId": "cc05751a-14e9-4a13-dbca-2701f11b220d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Data\n",
        "IMAGE_SIZE = [512, 512]\n",
        "GCS_PATH =file_path + '/tfrecords-jpeg-512x512'\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "TRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/train/*.tfrec')\n",
        "VALIDATION_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/val/*.tfrec')\n",
        "TEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/test/*.tfrec') \n",
        "\n",
        "CLASSES = ['pink primrose',    'hard-leaved pocket orchid', 'canterbury bells', 'sweet pea',     'wild geranium',     'tiger lily',           'moon orchid',              'bird of paradise', 'monkshood',        'globe thistle',         # 00 - 09\n",
        "           'snapdragon',       \"colt's foot\",               'king protea',      'spear thistle', 'yellow iris',       'globe-flower',         'purple coneflower',        'peruvian lily',    'balloon flower',   'giant white arum lily', # 10 - 19\n",
        "           'fire lily',        'pincushion flower',         'fritillary',       'red ginger',    'grape hyacinth',    'corn poppy',           'prince of wales feathers', 'stemless gentian', 'artichoke',        'sweet william',         # 20 - 29\n",
        "           'carnation',        'garden phlox',              'love in the mist', 'cosmos',        'alpine sea holly',  'ruby-lipped cattleya', 'cape flower',              'great masterwort', 'siam tulip',       'lenten rose',           # 30 - 39\n",
        "           'barberton daisy',  'daffodil',                  'sword lily',       'poinsettia',    'bolero deep blue',  'wallflower',           'marigold',                 'buttercup',        'daisy',            'common dandelion',      # 40 - 49\n",
        "           'petunia',          'wild pansy',                'primula',          'sunflower',     'lilac hibiscus',    'bishop of llandaff',   'gaura',                    'geranium',         'orange dahlia',    'pink-yellow dahlia',    # 50 - 59\n",
        "           'cautleya spicata', 'japanese anemone',          'black-eyed susan', 'silverbush',    'californian poppy', 'osteospermum',         'spring crocus',            'iris',             'windflower',       'tree poppy',            # 60 - 69\n",
        "           'gazania',          'azalea',                    'water lily',       'rose',          'thorn apple',       'morning glory',        'passion flower',           'lotus',            'toad lily',        'anthurium',             # 70 - 79\n",
        "           'frangipani',       'clematis',                  'hibiscus',         'columbine',     'desert-rose',       'tree mallow',          'magnolia',                 'cyclamen ',        'watercress',       'canna lily',            # 80 - 89\n",
        "           'hippeastrum ',     'bee balm',                  'pink quill',       'foxglove',      'bougainvillea',     'camellia',             'mallow',                   'mexican petunia',  'bromelia',         'blanket flower',        # 90 - 99\n",
        "           'trumpet creeper',  'blackberry lily',           'common tulip',     'wild rose']                                                                                                                                               # 100 - 102\n",
        "\n",
        "\n",
        "def decode_image(image_data):\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n",
        "    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size needed for TPU\n",
        "    return image\n",
        "\n",
        "def read_labeled_tfrecord(example):\n",
        "    LABELED_TFREC_FORMAT = {\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
        "        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n",
        "    }\n",
        "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
        "    image = decode_image(example['image'])\n",
        "    label = tf.cast(example['class'], tf.int32)\n",
        "    return image, label # returns a dataset of (image, label) pairs\n",
        "\n",
        "def read_unlabeled_tfrecord(example):\n",
        "    UNLABELED_TFREC_FORMAT = {\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
        "        \"id\": tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\n",
        "        # class is missing, this competitions's challenge is to predict flower classes for the test dataset\n",
        "    }\n",
        "    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n",
        "    image = decode_image(example['image'])\n",
        "    idnum = example['id']\n",
        "    return image, idnum # returns a dataset of image(s)\n",
        "\n",
        "def load_dataset(filenames, labeled=True, ordered=False):\n",
        "    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n",
        "    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n",
        "\n",
        "    ignore_order = tf.data.Options()\n",
        "    if not ordered:\n",
        "        ignore_order.experimental_deterministic = False # disable order, increase speed\n",
        "\n",
        "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n",
        "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
        "    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord, num_parallel_calls=AUTO)\n",
        "    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "n9_WsXK89bWF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Data Pipelines\n",
        "\n",
        "def data_augment(image, label):\n",
        "    # Thanks to the dataset.prefetch(AUTO)\n",
        "    # statement in the next function (below), this happens essentially\n",
        "    # for free on TPU. Data pipeline code is executed on the \"CPU\"\n",
        "    # part of the TPU while the TPU itself is computing gradients.\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    #image = tf.image.random_saturation(image, 0, 2)\n",
        "    return image, label   \n",
        "\n",
        "def get_training_dataset():\n",
        "    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n",
        "    dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n",
        "    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n",
        "    dataset = dataset.shuffle(2048)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
        "    return dataset\n",
        "\n",
        "def get_validation_dataset(ordered=False):\n",
        "    dataset = load_dataset(VALIDATION_FILENAMES, labeled=True, ordered=ordered)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.cache()\n",
        "    dataset = dataset.prefetch(AUTO)\n",
        "    return dataset\n",
        "\n",
        "def get_test_dataset(ordered=False):\n",
        "    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.prefetch(AUTO)\n",
        "    return dataset\n",
        "\n",
        "def count_data_items(filenames):\n",
        "    # the number of data items is written in the name of the .tfrec\n",
        "    # files, i.e. flowers00-230.tfrec = 230 data items\n",
        "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
        "    return np.sum(n)\n",
        "\n",
        "NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n",
        "NUM_VALIDATION_IMAGES = count_data_items(VALIDATION_FILENAMES)\n",
        "NUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\n",
        "print('Dataset: {} training images, {} validation images, {} unlabeled test images'.format(NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES))"
      ],
      "metadata": {
        "id": "IAhjzJb9-JM2",
        "outputId": "752c867d-5f2b-4428-bdd6-6babaa8afbff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: 12753 training images, 3712 validation images, 7382 unlabeled test images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the batch size. This will be 16 with TPU off and 128 (=16*8) with TPU on\n",
        "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
        "\n",
        "ds_train = get_training_dataset()\n",
        "ds_valid = get_validation_dataset()\n",
        "ds_test = get_test_dataset()\n",
        "\n",
        "print(\"Training:\", ds_train)\n",
        "print (\"Validation:\", ds_valid)\n",
        "print(\"Test:\", ds_test)"
      ],
      "metadata": {
        "id": "n69Dk8xf-XiF",
        "outputId": "62cdb572-2816-4550-cbca-140844f6d4b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training: <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 512, 512, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n",
            "Validation: <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 512, 512, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n",
            "Test: <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 512, 512, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(threshold=15, linewidth=80)\n",
        "\n",
        "print(\"Training data shapes:\")\n",
        "for image, label in ds_train.take(3):\n",
        "    print(image.numpy().shape, label.numpy().shape)\n",
        "print(\"Training data label examples:\", label.numpy())"
      ],
      "metadata": {
        "id": "r-J5c3b1-ccd",
        "outputId": "a7fdef72-3714-48c2-a29f-5c77ce729086",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shapes:\n",
            "(16, 512, 512, 3) (16,)\n",
            "(16, 512, 512, 3) (16,)\n",
            "(16, 512, 512, 3) (16,)\n",
            "Training data label examples: [56 67 91 ... 67 14 93]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Explore Data"
      ],
      "metadata": {
        "id": "4SwaYcM2DyKk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Define Model : CNN Models"
      ],
      "metadata": {
        "id": "mLAd8YG2D10m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining Baseline Model"
      ],
      "metadata": {
        "id": "LzkAcDokFmZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, BatchNormalization\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "EPOCHS = 20"
      ],
      "metadata": {
        "id": "dzNFgpgcFpWE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense, Activation, Conv2D, MaxPool2D, Dropout, Flatten\n",
        "gu_seed=tf.keras.initializers.GlorotUniform(seed=1)\n",
        "\n",
        "EPOCHS = 20\n",
        "with strategy.scope():\n",
        "    \"\"\"pretrained_model = tf.keras.applications.VGG16(\n",
        "        weights='imagenet',\n",
        "        include_top=False ,\n",
        "        input_shape=[*IMAGE_SIZE, 3]\n",
        "    )\n",
        "    pretrained_model.trainable = False\n",
        "    \n",
        "    model = tf.keras.Sequential(([\n",
        "        # To a base pretrained on ImageNet to extract features from images...\n",
        "        pretrained_model,\n",
        "        # ... attach a new head to act as a classifier.\n",
        "        tf.keras.layers.GlobalAveragePooling2D(),\n",
        "        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n",
        "    ]))\"\"\"\n",
        "    model0 = tf.keras.Sequential()\n",
        "    model0.add(Conv2D(32, kernel_size=(5,5), kernel_initializer=gu_seed, padding='same', activation='relu', input_shape=(512,512,3)))\n",
        "    model0.add(MaxPool2D(pool_size=(3,3)))\n",
        "    model0.add(Dropout(0.25))\n",
        "    \n",
        "    model0.add(Conv2D(64, kernel_size=(5,5), kernel_initializer=gu_seed, padding='same', activation='relu'))\n",
        "    model0.add(MaxPool2D(pool_size=(3,3)))\n",
        "    model0.add(Dropout(0.25))\n",
        "    \n",
        "    model0.add(Conv2D(64, kernel_size=(5,5), kernel_initializer=gu_seed, padding='same', activation='relu'))\n",
        "    model0.add(MaxPool2D(pool_size=(3,3)))\n",
        "    model0.add(Dropout(0.25))\n",
        "    \n",
        "    model0.add(Flatten())\n",
        "    model0.add(Dense(len(CLASSES), activation='softmax'))\n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "    model2 = tf.keras.Sequential()\n",
        "    model2.add(Conv2D(32, kernel_size=(5,5), padding='same', activation='relu', input_shape=(512,512,1)))\n",
        "    model2.add(MaxPool2D(pool_size=(3,3)))\n",
        "    model2.add(Dropout(0.25))\n",
        "    \n",
        "    model2.add(Conv2D(64, kernel_size=(5,5), padding='same', activation='relu'))\n",
        "    model2.add(MaxPool2D(pool_size=(3,3)))\n",
        "    model2.add(Dropout(0.25))\n",
        "    \n",
        "    model2.add(Flatten())\n",
        "    model2.add(Dense(len(CLASSES), activation='softmax'))\"\"\""
      ],
      "metadata": {
        "id": "oFbaMkr-F31r"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model0.compile(\n",
        "    optimizer='adam',\n",
        "    loss = 'sparse_categorical_crossentropy',\n",
        "    metrics=['sparse_categorical_accuracy'],\n",
        ")\n",
        "\n",
        "model0.summary()"
      ],
      "metadata": {
        "id": "UX6JYvH4F7c4",
        "outputId": "133a3623-908c-4c31-f954-cca197275d7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 512, 512, 32)      2432      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 170, 170, 32)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 170, 170, 32)      0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 170, 170, 64)      51264     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 56, 56, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 56, 56, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 56, 56, 64)        102464    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 18, 18, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 18, 18, 64)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 20736)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 104)               2156648   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,312,808\n",
            "Trainable params: 2,312,808\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define learning rate schedule\n",
        "from matplotlib import pyplot as plt\n",
        "def adapt_learning_rate(epoch,\n",
        "                   start_lr = 0.0005, min_lr = 0.00005, max_lr = 0.0001,\n",
        "                   rampup_epochs = 8, sustain_epochs = 0,\n",
        "                   exp_decay = 0.8):\n",
        "\n",
        "    def lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay):\n",
        "        if epoch < rampup_epochs:\n",
        "            lr = ((max_lr - start_lr) /\n",
        "                  rampup_epochs * epoch + start_lr)\n",
        "        elif epoch < rampup_epochs + sustain_epochs:\n",
        "            lr = max_lr\n",
        "        else:\n",
        "            lr = ((max_lr - min_lr) *\n",
        "                  exp_decay**(epoch - rampup_epochs - sustain_epochs) +\n",
        "                  min_lr)\n",
        "        return lr\n",
        "    return lr(epoch,\n",
        "              start_lr,\n",
        "              min_lr,\n",
        "              max_lr,\n",
        "              rampup_epochs,\n",
        "              sustain_epochs,\n",
        "              exp_decay)\n",
        "\n",
        "lr_callback = tf.keras.callbacks.LearningRateScheduler(adapt_learning_rate, verbose=True)\n",
        "\n",
        "rng = [i for i in range(EPOCHS)]\n",
        "y = [adapt_learning_rate(x) for x in rng]\n",
        "plt.plot(rng, y)\n",
        "print(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))"
      ],
      "metadata": {
        "id": "C7BtK0XhLT8J",
        "outputId": "26c8a134-c847-44df-8598-ec71184a6174",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate schedule: 0.0005 to 0.0005 to 5.43e-05\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training epochs\n",
        "EPOCHS = 20\n",
        "STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n",
        "\n",
        "history = model0.fit(\n",
        "    ds_train,\n",
        "    validation_data=ds_valid,\n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch=STEPS_PER_EPOCH,\n",
        "    callbacks=[lr_callback],\n",
        ")"
      ],
      "metadata": {
        "id": "C7qHIbkuF9nw",
        "outputId": "694c5248-31c7-4ce7-d67d-8432e85d1853",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 1/20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Baseline Overview"
      ],
      "metadata": {
        "id": "i7CU2b4kEH8p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Graphs"
      ],
      "metadata": {
        "id": "i2gRrbIaGau7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display_training_curves(\n",
        "    history.history['loss'],\n",
        "    history.history['val_loss'],\n",
        "    'loss',\n",
        "    211,\n",
        ")\n",
        "display_training_curves(\n",
        "    history.history['sparse_categorical_accuracy'],\n",
        "    history.history['val_sparse_categorical_accuracy'],\n",
        "    'accuracy',\n",
        "    212,\n",
        ")"
      ],
      "metadata": {
        "id": "s4aGRNPsENVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confusion matrix"
      ],
      "metadata": {
        "id": "2THuAb_HGer8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cmdataset = get_validation_dataset(ordered=True)\n",
        "images_ds = cmdataset.map(lambda image, label: image)\n",
        "labels_ds = cmdataset.map(lambda image, label: label).unbatch()\n",
        "\n",
        "cm_correct_labels = next(iter(labels_ds.batch(NUM_VALIDATION_IMAGES))).numpy()\n",
        "cm_probabilities = model0.predict(images_ds)\n",
        "cm_predictions = np.argmax(cm_probabilities, axis=-1)\n",
        "\n",
        "labels = range(len(CLASSES))\n",
        "cmat = confusion_matrix(\n",
        "    cm_correct_labels,\n",
        "    cm_predictions,\n",
        "    labels=labels,\n",
        ")\n",
        "cmat = (cmat.T / cmat.sum(axis=1)).T # normalize"
      ],
      "metadata": {
        "id": "XlJRgPPcGMuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "score = f1_score(\n",
        "    cm_correct_labels,\n",
        "    cm_predictions,\n",
        "    labels=labels,\n",
        "    average='macro',\n",
        ")\n",
        "precision = precision_score(\n",
        "    cm_correct_labels,\n",
        "    cm_predictions,\n",
        "    labels=labels,\n",
        "    average='macro',\n",
        ")\n",
        "recall = recall_score(\n",
        "    cm_correct_labels,\n",
        "    cm_predictions,\n",
        "    labels=labels,\n",
        "    average='macro',\n",
        ")\n",
        "display_confusion_matrix(cmat, score, precision, recall)"
      ],
      "metadata": {
        "id": "ThuvcQQDGTar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "confusion = confusion_matrix(\n",
        "    cm_correct_labels,\n",
        "    cm_predictions,\n",
        "    labels=labels,\n",
        ")\n",
        "\n",
        "total = np.sum(confusion)\n",
        "accuracy = np.trace(confusion) / float(total)\n",
        "specificity = np.diag(confusion)[0] / np.sum(confusion[0])\n",
        "sensitivity = np.diag(confusion)[1] / np.sum(confusion[1])\n",
        "ppv = np.diag(confusion)[1] / np.sum(confusion[:, 1])\n",
        "npv = np.diag(confusion)[0] / np.sum(confusion[:, 0])\n",
        "\n",
        "# Print the results\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Specificity:\", specificity)\n",
        "print(\"Sensitivity:\", sensitivity)\n",
        "print(\"PPV:\", ppv)\n",
        "print(\"NPV:\", npv)"
      ],
      "metadata": {
        "id": "WaUHxKiHGXuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet50 (poor accuracy)"
      ],
      "metadata": {
        "id": "I-MuX5soEFdF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining Model"
      ],
      "metadata": {
        "id": "diXaV8e3Hxkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense, Activation, Conv2D, MaxPool2D, Dropout, Flatten\n",
        "gu_seed=tf.keras.initializers.GlorotUniform(seed=1)\n",
        "\n",
        "EPOCHS = 20\n",
        "with strategy.scope():\n",
        "    \"\"\"pretrained_model = tf.keras.applications.VGG16(\n",
        "        weights='imagenet',\n",
        "        include_top=False ,\n",
        "        input_shape=[*IMAGE_SIZE, 3]\n",
        "    )\n",
        "    pretrained_model.trainable = False\n",
        "    \n",
        "    model = tf.keras.Sequential(([\n",
        "        # To a base pretrained on ImageNet to extract features from images...\n",
        "        pretrained_model,\n",
        "        # ... attach a new head to act as a classifier.\n",
        "        tf.keras.layers.GlobalAveragePooling2D(),\n",
        "        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n",
        "    ]))\"\"\"\n",
        "    model0 = tf.keras.Sequential()\n",
        "    model0.add(Conv2D(32, kernel_size=(5,5), kernel_initializer=gu_seed, padding='same', activation='relu', input_shape=(512,512,3)))\n",
        "    model0.add(MaxPool2D(pool_size=(3,3)))\n",
        "    model0.add(Dropout(0.25))\n",
        "    \n",
        "    model0.add(Conv2D(64, kernel_size=(5,5), kernel_initializer=gu_seed, padding='same', activation='relu'))\n",
        "    model0.add(MaxPool2D(pool_size=(3,3)))\n",
        "    model0.add(Dropout(0.25))\n",
        "    \n",
        "    model0.add(Conv2D(64, kernel_size=(5,5), kernel_initializer=gu_seed, padding='same', activation='relu'))\n",
        "    model0.add(MaxPool2D(pool_size=(3,3)))\n",
        "    model0.add(Dropout(0.25))\n",
        "    \n",
        "    model0.add(Flatten())\n",
        "    model0.add(Dense(len(CLASSES), activation='softmax'))\n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "    model2 = tf.keras.Sequential()\n",
        "    model2.add(Conv2D(32, kernel_size=(5,5), padding='same', activation='relu', input_shape=(512,512,1)))\n",
        "    model2.add(MaxPool2D(pool_size=(3,3)))\n",
        "    model2.add(Dropout(0.25))\n",
        "    \n",
        "    model2.add(Conv2D(64, kernel_size=(5,5), padding='same', activation='relu'))\n",
        "    model2.add(MaxPool2D(pool_size=(3,3)))\n",
        "    model2.add(Dropout(0.25))\n",
        "    \n",
        "    model2.add(Flatten())\n",
        "    model2.add(Dense(len(CLASSES), activation='softmax'))\"\"\"\n",
        "\n",
        "\n",
        "EPOCHS = 20\n",
        "with strategy.scope():\n",
        "    pretrained_model = tf.keras.applications.resnet50.ResNet50(\n",
        "        weights='imagenet',\n",
        "        include_top=False ,\n",
        "        input_shape=[*IMAGE_SIZE, 3]\n",
        "        \n",
        "    )\n",
        "    pretrained_model.trainable = True\n",
        "    \n",
        "    modelTwo = tf.keras.Sequential([\n",
        "        pretrained_model,\n",
        "        tf.keras.layers.GlobalAveragePooling2D(),\n",
        "        tf.keras.layers.BatchNormalization(),  \n",
        "        tf.keras.layers.Dropout(0.5), \n",
        "        \n",
        "    model0.add(Conv2D(64, kernel_size=(5,5), kernel_initializer=gu_seed, padding='same', activation='relu'))\n",
        "    model0.add(MaxPool2D(pool_size=(3,3)))\n",
        "    model0.add(Dropout(0.25))\n",
        "    \n",
        "    model0.add(Conv2D(64, kernel_size=(5,5), kernel_initializer=gu_seed, padding='same', activation='relu'))\n",
        "    model0.add(MaxPool2D(pool_size=(3,3)))\n",
        "    model0.add(Dropout(0.25))\n",
        "    \n",
        "    model0.add(Flatten())        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n",
        "    ])\n",
        "    \n",
        "    \n",
        "    model = tf.keras.Sequential([\n",
        "        pretrained_model,\n",
        "        tf.keras.layers.GlobalAveragePooling2D(),\n",
        "        tf.keras.layers.BatchNormalization(),  \n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(1024, activation = \"relu\"),\n",
        "        tf.keras.layers.BatchNormalization(),  \n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(2048, activation = \"relu\"),\n",
        "        tf.keras.layers.BatchNormalization(),  \n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(2048, activation = \"relu\"),\n",
        "        tf.keras.layers.BatchNormalization(),  \n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(1024, activation = \"relu\"),\n",
        "        tf.keras.layers.BatchNormalization(),  \n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n",
        "    ])"
      ],
      "metadata": {
        "id": "VyPclkAyDzlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelTwo.compile(\n",
        "    optimizer='adam',\n",
        "    loss = 'sparse_categorical_crossentropy',\n",
        "    metrics=['sparse_categorical_accuracy'],\n",
        ")\n",
        "\n",
        "modelTwo.summary()"
      ],
      "metadata": {
        "id": "5Rm6r-UYHb4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adapt_learning_rate(epoch,\n",
        "                   start_lr = 0.0005, min_lr = 0.00005, max_lr = 0.0001,\n",
        "                   rampup_epochs = 8, sustain_epochs = 0,\n",
        "                   exp_decay = 0.8):\n",
        "\n",
        "    def lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay):\n",
        "        if epoch < rampup_epochs:\n",
        "            lr = ((max_lr - start_lr) /\n",
        "                  rampup_epochs * epoch + start_lr)\n",
        "        elif epoch < rampup_epochs + sustain_epochs:\n",
        "            lr = max_lr\n",
        "        else:\n",
        "            lr = ((max_lr - min_lr) *\n",
        "                  exp_decay**(epoch - rampup_epochs - sustain_epochs) +\n",
        "                  min_lr)\n",
        "        return lr\n",
        "    return lr(epoch,\n",
        "              start_lr,\n",
        "              min_lr,\n",
        "              max_lr,\n",
        "              rampup_epochs,\n",
        "              sustain_epochs,\n",
        "              exp_decay)\n",
        "\n",
        "lr_callback = tf.keras.callbacks.LearningRateScheduler(adapt_learning_rate, verbose=True)\n",
        "\n",
        "rng = [i for i in range(EPOCHS)]\n",
        "y = [adapt_learning_rate(x) for x in rng]\n",
        "plt.plot(rng, y)\n",
        "print(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))"
      ],
      "metadata": {
        "id": "pB9atuLjHfTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training epochs\n",
        "EPOCHS = 20\n",
        "STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n",
        "\n",
        "history = modelTwo.fit(\n",
        "    ds_train,\n",
        "    validation_data=ds_valid,\n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch=STEPS_PER_EPOCH,\n",
        "    callbacks=[lr_callback],\n",
        ")"
      ],
      "metadata": {
        "id": "NdwkAnqIHiKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One interesting thing to notice is that even though the training accuracy increases significantly from the start, the model is rather slow to adapt to the patterns and learn to generalise to the validation data. This could be due to it taking much longer to change the weights of the ResNet50 model as the model itself should have set weights already."
      ],
      "metadata": {
        "id": "hb9X5FU_HnZV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Overview"
      ],
      "metadata": {
        "id": "tekMFIF1H7cE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display_training_curves(\n",
        "    history.history['loss'],\n",
        "    history.history['val_loss'],\n",
        "    'loss',\n",
        "    211,\n",
        ")\n",
        "display_training_curves(\n",
        "    history.history['sparse_categorical_accuracy'],\n",
        "    history.history['val_sparse_categorical_accuracy'],\n",
        "    'accuracy',\n",
        "    212,\n",
        ")"
      ],
      "metadata": {
        "id": "KTAnbQHqIBQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cmdataset = get_validation_dataset(ordered=True)\n",
        "images_ds = cmdataset.map(lambda image, label: image)\n",
        "labels_ds = cmdataset.map(lambda image, label: label).unbatch()\n",
        "\n",
        "cm_correct_labels = next(iter(labels_ds.batch(NUM_VALIDATION_IMAGES))).numpy()\n",
        "cm_probabilities = modelTwo.predict(images_ds)\n",
        "cm_predictions = np.argmax(cm_probabilities, axis=-1)\n",
        "\n",
        "labels = range(len(CLASSES))\n",
        "cmat = confusion_matrix(\n",
        "    cm_correct_labels,\n",
        "    cm_predictions,\n",
        "    labels=labels,\n",
        ")\n",
        "cmat = (cmat.T / cmat.sum(axis=1)).T # normalize"
      ],
      "metadata": {
        "id": "wJoNm7mEIE1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "score = f1_score(\n",
        "    cm_correct_labels,\n",
        "    cm_predictions,\n",
        "    labels=labels,\n",
        "    average='macro',\n",
        ")\n",
        "precision = precision_score(\n",
        "    cm_correct_labels,\n",
        "    cm_predictions,\n",
        "    labels=labels,\n",
        "    average='macro',\n",
        ")\n",
        "recall = recall_score(\n",
        "    cm_correct_labels,\n",
        "    cm_predictions,\n",
        "    labels=labels,\n",
        "    average='macro',\n",
        ")\n",
        "display_confusion_matrix(cmat, score, precision, recall)"
      ],
      "metadata": {
        "id": "dkC5nn8-IHlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "confusion = confusion_matrix(\n",
        "    cm_correct_labels,\n",
        "    cm_predictions,\n",
        "    labels=labels,\n",
        ")\n",
        "\n",
        "total = np.sum(confusion)\n",
        "accuracy = np.trace(confusion) / float(total)\n",
        "specificity = np.diag(confusion)[0] / np.sum(confusion[0])\n",
        "sensitivity = np.diag(confusion)[1] / np.sum(confusion[1])\n",
        "ppv = np.diag(confusion)[1] / np.sum(confusion[:, 1])\n",
        "npv = np.diag(confusion)[0] / np.sum(confusion[:, 0])\n",
        "\n",
        "# Print the results\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Specificity:\", specificity)\n",
        "print(\"Sensitivity:\", sensitivity)\n",
        "print(\"PPV:\", ppv)\n",
        "print(\"NPV:\", npv)"
      ],
      "metadata": {
        "id": "l9eoweOMIJTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The graphs above with a heavy fluctuation of model validation loss at the start indicates that my initial learning rate may be too high. However as both curves eventually start to move to each other, it is concluded that the network's traning graph is likely to have one big global minima (second image) rather than many local minima (first image). This means that the learning rate shouldn't have too much of an effect on the network and the network's performace is near maximised at 91% accuracy."
      ],
      "metadata": {
        "id": "I8SYelvlING9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Xception"
      ],
      "metadata": {
        "id": "k09NYVvNIfde"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining Model"
      ],
      "metadata": {
        "id": "hGjcS5QBIlsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "with strategy.scope():\n",
        "    pretrained_model = tf.keras.applications.Xception(\n",
        "        weights='imagenet',\n",
        "        include_top=False ,\n",
        "        input_shape=[*IMAGE_SIZE, 3]\n",
        "        \n",
        "    )\n",
        "    pretrained_model.trainable = False\n",
        "    \n",
        "    modelThree = tf.keras.Sequential([\n",
        "        pretrained_model,\n",
        "        tf.keras.layers.GlobalAveragePooling2D(),\n",
        "        tf.keras.layers.BatchNormalization(),  \n",
        "        tf.keras.layers.Dense(1024, activation = \"relu\"),\n",
        "        tf.keras.layers.BatchNormalization(),  \n",
        "        tf.keras.layers.Dropout(0.25),\n",
        "        tf.keras.layers.Dense(2048, activation = \"relu\"),\n",
        "        tf.keras.layers.BatchNormalization(),  \n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Dense(4096, activation = \"relu\"),\n",
        "        tf.keras.layers.BatchNormalization(),  \n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(2048, activation = \"relu\"),\n",
        "        tf.keras.layers.BatchNormalization(), \n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Dense(1024, activation = \"relu\"),\n",
        "        tf.keras.layers.BatchNormalization(),  \n",
        "        tf.keras.layers.Dense(512, activation = \"relu\"),\n",
        "        tf.keras.layers.BatchNormalization(),  \n",
        "        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n",
        "    ])"
      ],
      "metadata": {
        "id": "0g7a9PkGIfHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelThree.compile(\n",
        "    optimizer='adam',\n",
        "    loss = 'sparse_categorical_crossentropy',\n",
        "    metrics=['sparse_categorical_accuracy'],\n",
        ")\n",
        "\n",
        "modelThree.summary()"
      ],
      "metadata": {
        "id": "V9F417GaJv55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adapt_learning_rate(epoch,\n",
        "                   start_lr = 0.0005, min_lr = 0.00005, max_lr = 0.0001,\n",
        "                   rampup_epochs = 6, sustain_epochs = 0,\n",
        "                   exp_decay = 0.8):\n",
        "\n",
        "    def lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay):\n",
        "        if epoch < rampup_epochs:\n",
        "            lr = ((max_lr - start_lr) /\n",
        "                  rampup_epochs * epoch + start_lr)\n",
        "        elif epoch < rampup_epochs + sustain_epochs:\n",
        "            lr = max_lr\n",
        "        else:\n",
        "            lr = ((max_lr - min_lr) *\n",
        "                  exp_decay**(epoch - rampup_epochs - sustain_epochs) +\n",
        "                  min_lr)\n",
        "        return lr\n",
        "    return lr(epoch,\n",
        "              start_lr,\n",
        "              min_lr,\n",
        "              max_lr,\n",
        "              rampup_epochs,\n",
        "              sustain_epochs,\n",
        "              exp_decay)\n",
        "\n",
        "lr_callback = tf.keras.callbacks.LearningRateScheduler(adapt_learning_rate, verbose=True)\n",
        "\n",
        "rng = [i for i in range(EPOCHS)]\n",
        "y = [adapt_learning_rate(x) for x in rng]\n",
        "plt.plot(rng, y)\n",
        "print(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))"
      ],
      "metadata": {
        "id": "VxoPANzQJ0s3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training epochs\n",
        "EPOCHS = 20\n",
        "STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n",
        "\n",
        "history = modelThree.fit(\n",
        "    ds_train,\n",
        "    validation_data=ds_valid,\n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch=STEPS_PER_EPOCH,\n",
        "    callbacks=[lr_callback],\n",
        ")"
      ],
      "metadata": {
        "id": "CCY3rmsmJ1lF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Overview"
      ],
      "metadata": {
        "id": "smuzu-6wIr64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display_training_curves(\n",
        "    history.history['loss'],\n",
        "    history.history['val_loss'],\n",
        "    'loss',\n",
        "    211,\n",
        ")\n",
        "display_training_curves(\n",
        "    history.history['sparse_categorical_accuracy'],\n",
        "    history.history['val_sparse_categorical_accuracy'],\n",
        "    'accuracy',\n",
        "    212,\n",
        ")"
      ],
      "metadata": {
        "id": "N5HXodU5J49A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cmdataset = get_validation_dataset(ordered=True)\n",
        "images_ds = cmdataset.map(lambda image, label: image)\n",
        "labels_ds = cmdataset.map(lambda image, label: label).unbatch()\n",
        "\n",
        "cm_correct_labels = next(iter(labels_ds.batch(NUM_VALIDATION_IMAGES))).numpy()\n",
        "cm_probabilities = modelThree.predict(images_ds)\n",
        "cm_predictions = np.argmax(cm_probabilities, axis=-1)\n",
        "\n",
        "labels = range(len(CLASSES))\n",
        "cmat = confusion_matrix(\n",
        "    cm_correct_labels,\n",
        "    cm_predictions,\n",
        "    labels=labels,\n",
        ")\n",
        "cmat = (cmat.T / cmat.sum(axis=1)).T # normalize"
      ],
      "metadata": {
        "id": "k0_FnoNqJ6-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "score = f1_score(\n",
        "    cm_correct_labels,\n",
        "    cm_predictions,\n",
        "    labels=labels,\n",
        "    average='macro',\n",
        ")\n",
        "precision = precision_score(\n",
        "    cm_correct_labels,\n",
        "    cm_predictions,\n",
        "    labels=labels,\n",
        "    average='macro',\n",
        ")\n",
        "recall = recall_score(\n",
        "    cm_correct_labels,\n",
        "    cm_predictions,\n",
        "    labels=labels,\n",
        "    average='macro',\n",
        ")\n",
        "display_confusion_matrix(cmat, score, precision, recall)"
      ],
      "metadata": {
        "id": "SHLMUGRhKAHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "confusion = confusion_matrix(\n",
        "    cm_correct_labels,\n",
        "    cm_predictions,\n",
        "    labels=labels,\n",
        ")\n",
        "\n",
        "total = np.sum(confusion)\n",
        "accuracy = np.trace(confusion) / float(total)\n",
        "specificity = np.diag(confusion)[0] / np.sum(confusion[0])\n",
        "sensitivity = np.diag(confusion)[1] / np.sum(confusion[1])\n",
        "ppv = np.diag(confusion)[1] / np.sum(confusion[:, 1])\n",
        "npv = np.diag(confusion)[0] / np.sum(confusion[:, 0])\n",
        "\n",
        "# Print the results\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Specificity:\", specificity)\n",
        "print(\"Sensitivity:\", sensitivity)\n",
        "print(\"PPV:\", ppv)\n",
        "print(\"NPV:\", npv)"
      ],
      "metadata": {
        "id": "Y_XG3hhGKCYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 7: Evaluate Predictions"
      ],
      "metadata": {
        "id": "_plhqfBFEQdq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rOHVp78aERu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 8: Make Test Predictions"
      ],
      "metadata": {
        "id": "tb2haAJMEYni"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1IbSltFEEbxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 9: Make a submission"
      ],
      "metadata": {
        "id": "brpjwmyMEcMe"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PpwxImUbEdm2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}