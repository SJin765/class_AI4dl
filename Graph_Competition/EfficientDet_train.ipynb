{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNnomUAICAKC3Ft6m5LXniu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SJin765/class_AI4dl/blob/main/Graph_Competition/EfficientDet_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Benetech | EfficientDet [Train]\n",
        "\n",
        "https://www.kaggle.com/code/alejopaullier/benetech-efficientdet-train"
      ],
      "metadata": {
        "id": "h4nATJM3hNQc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import EfficientDet, Pytorch"
      ],
      "metadata": {
        "id": "S-0ng6X7hfcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pycocotools"
      ],
      "metadata": {
        "id": "n7i2KEXJht4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFVsMVjqhMsg"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0, \"../input/timm-efficientdet-pytorch\")\n",
        "sys.path.insert(0, \"../input/omegaconf\")\n",
        "sys.path.insert(0, \"../input/albumentations\")\n",
        "\n",
        "import albumentations as A\n",
        "import copy\n",
        "import cv2\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "import multiprocessing\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import PIL\n",
        "import random\n",
        "import time\n",
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "from colorama import Fore, Back, Style\n",
        "from datetime import datetime, timedelta\n",
        "from glob import glob\n",
        "from pprint import pprint\n",
        "from sklearn.model_selection import KFold, GroupKFold, StratifiedKFold\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
        "from torch.optim import lr_scheduler\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "c_  = Fore.GREEN\n",
        "sr_ = Style.RESET_ALL\n",
        "print(f\"There are {multiprocessing.cpu_count()} CPUs available\")\n",
        "print()\n",
        "!mkdir logs\n",
        "!mkdir saved_models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuration"
      ],
      "metadata": {
        "id": "MkvR2N0OjfGV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter"
      ],
      "metadata": {
        "id": "HjZPmvl0jomK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 구글 드라이브에 내가 올려놓은 파일을 이용할 경우\n",
        "# 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# file_path = '/content/drive/MyDrive/benetech-making-graphs-accessible'"
      ],
      "metadata": {
        "id": "5m_3fUkAkca9",
        "outputId": "0637abf8-641e-4ffe-93db-9b2bb46fc3a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 드라이브 내 압축풀기\n",
        "import zipfile\n",
        "\n",
        "zip_file_path = '/content/drive/MyDrive/benetech-making-graphs-accessible.zip'\n",
        "extract_path = '/content/drive/MyDrive/benetech-making-graphs-accessible'\n",
        "\n",
        "# 압축 파일 열기\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_file:\n",
        "    # 압축 파일 내 폴더 목록 확인\n",
        "    folder_list = [name for name in zip_file.namelist() if name.endswith('/')]\n",
        "\n",
        "    # 폴더 내용물 확인\n",
        "    for folder_name in folder_list:\n",
        "        print(f\"Folder: {folder_name}\")\n",
        "        file_list = zip_file.namelist()\n",
        "\n",
        "        # 폴더 내 파일 목록 확인\n",
        "        for file_name in file_list:\n",
        "            if file_name.startswith(folder_name) and not file_name.endswith('/'):\n",
        "                print(f\"File: {file_name}\")\n",
        "\n",
        "    # 압축 파일 해제\n",
        "    zip_file.extractall(extract_path)"
      ],
      "metadata": {
        "id": "0b7_7JV9aRlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class config:\n",
        "    BATCH_SIZE_TRAIN = 4\n",
        "    BATCH_SIZE_VALID = 2\n",
        "    DEBUG = False\n",
        "    DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    EPOCHS = 5\n",
        "    FOLDS = 5\n",
        "    LR = 2e-4\n",
        "    MIN_LR = 1e-6\n",
        "    NUM_WORKERS = multiprocessing.cpu_count()\n",
        "    RESOLUTION = 512\n",
        "    SAMPLE = 30_000\n",
        "    SEED = 42\n",
        "    SCHEDULER = 'CosineAnnealingLR'\n",
        "    T_0 = 25\n",
        "    T_MAX = int(30_000/BATCH_SIZE_TRAIN*EPOCHS)+50\n",
        "    WARMUP_EPOCHS = 0\n",
        "    WEIGHT_DECAY = 1e-6\n",
        "    \n",
        "    \n",
        "class paths:\n",
        "    TRAIN_ANNOTATIONS_FOLDER = \"/content/drive/MyDrive/benetech-making-graphs-accessible/train/annotations/\"\n",
        "    TRAIN_IMAGES_FOLDER = \"/content/drive/MyDrive/benetech-making-graphs-accessible/train/images/\""
      ],
      "metadata": {
        "id": "QEnUANNZh9Ke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils"
      ],
      "metadata": {
        "id": "XvmfDgG3jWo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_stoi(df):\n",
        "    \"\"\"Get String to Index dictionary\"\"\"\n",
        "    stoi = {}\n",
        "    for idx, string in enumerate(df.label.unique()):\n",
        "        stoi[string] = idx + 1\n",
        "    itos = {item[1]: item[0] for item in stoi.items()}\n",
        "    df = df.replace({\"label\": stoi})\n",
        "    return stoi\n",
        "\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(config.SEED)"
      ],
      "metadata": {
        "id": "TsowBJJAjYmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Competition Data"
      ],
      "metadata": {
        "id": "g7SeKj6ih71-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/benetech-create-bounding-box-dataframe/train.csv\")\n",
        "print(f\"Dataframe shape is: {df.shape}\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "sMz9AYHJkyJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Pre-procesing"
      ],
      "metadata": {
        "id": "6--B7BCCk8Ef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_ids = df[\"image_id\"].unique().tolist()\n",
        "image_ids = random.sample(image_ids, config.SAMPLE)\n",
        "filter = df[(df[\"x0\"]<0) | (df[\"y0\"]<0) | (df[\"h\"]<=0) | (df[\"w\"]<=0)].index\n",
        "df = df[~df.index.isin(filter)]\n",
        "df = df[df[\"image_id\"].isin(image_ids)]\n",
        "stoi = get_stoi(df)\n",
        "pprint(stoi)\n",
        "config.NUM_CLASSES =  len(stoi)\n",
        "df = df[df[\"label\"].isin(list(stoi.keys()))]\n",
        "df = df.replace({\"label\": stoi})\n",
        "df.reset_index(inplace=True)\n",
        "print(f\"Dataframe shape is: {df.shape}\")\n",
        "print(f\"Number of classes: {config.NUM_CLASSES}\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "02VZAKCIk9qB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split into train, validation"
      ],
      "metadata": {
        "id": "er596wHblLBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gkf = GroupKFold(n_splits=config.FOLDS) # Seed for reproducibility\n",
        "X = df.loc[:, df.columns != \"label\"]\n",
        "y = df.loc[:, df.columns == \"label\"]\n",
        "groups = df.loc[:, df.columns == \"image_id\"]\n",
        "\n",
        "for fold, (train_index, val_index) in enumerate(gkf.split(X, y, groups)):\n",
        "    df.loc[val_index, 'fold'] = int(fold) # Assign to each row its Fold ID\n",
        "display(df.groupby(['fold','chart'])[\"index\"].count())"
      ],
      "metadata": {
        "id": "aK-45J8WlO35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Albumentations transformations\n",
        "\n"
      ],
      "metadata": {
        "id": "64W06qpllUap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_transforms():\n",
        "    return A.Compose(\n",
        "        [\n",
        "            A.Resize(height=config.RESOLUTION, width=config.RESOLUTION, p=1),\n",
        "            A.Normalize(p=1),\n",
        "            ToTensorV2(p=1.0),\n",
        "        ], \n",
        "        p=1.0, \n",
        "        bbox_params=A.BboxParams(\n",
        "            format='pascal_voc', min_area=0,  min_visibility=0, label_fields=['labels']\n",
        "        )\n",
        "    )\n",
        "\n",
        "def get_valid_transforms():\n",
        "    return A.Compose(\n",
        "        [\n",
        "            A.Resize(height=config.RESOLUTION, width=config.RESOLUTION, p=1.0),\n",
        "            A.Normalize(p=1),\n",
        "            ToTensorV2(p=1.0),\n",
        "        ], \n",
        "        p=1.0, \n",
        "        bbox_params=A.BboxParams(\n",
        "            format='pascal_voc', min_area=0, min_visibility=0, label_fields=['labels']\n",
        "        )\n",
        "    )"
      ],
      "metadata": {
        "id": "I2s9oQDmlUBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create custom PyTorch dataset"
      ],
      "metadata": {
        "id": "cgKHdh7RlhXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, df, transforms=None):\n",
        "        super().__init__()\n",
        "        self.df = df # pandas dataframe\n",
        "        self.transforms = transforms # albumentations transformations\n",
        "        self.image_ids = self.df[\"image_id\"].unique().tolist() # list with unique image IDs\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        \"\"\"\n",
        "        :return image: an augmented image as a numpy array.\n",
        "        :return target: a dictionary containing a tensor with the bboxes for the image (torch.Tensor),\n",
        "        a list of strings containing the bboxes labels and a tensor containing the image index.\n",
        "        :return image_id: the image ID. A unique identifier for each image. \n",
        "        \n",
        "        \"\"\"\n",
        "        image_id = self.image_ids[index] # select one image\n",
        "        image, boxes = self.load_image_and_boxes(index) # load the image and its associated bounding boxes\n",
        "        labels = self.get_labels(index)\n",
        "        target = {\n",
        "            'boxes' : boxes, \n",
        "            'labels' : labels, \n",
        "            'index' : torch.tensor([index])\n",
        "        }\n",
        "        transformed_image = self.transforms(**{\n",
        "            'image': image,\n",
        "            'bboxes': target['boxes'],\n",
        "            'labels': target[\"labels\"]\n",
        "        })\n",
        "        image = transformed_image['image']\n",
        "        _, new_h, new_w = image.shape\n",
        "        \n",
        "        # This creates a torch tensor of size (number_bboxes, 4) where each row is a bounding box:\n",
        "        target['boxes'] = torch.stack(tuple(map(torch.tensor, zip(*transformed_image['bboxes'])))).permute(1, 0)\n",
        "        target['boxes'][:,[0,1,2,3]] = target['boxes'][:,[1,0,3,2]]  # Required: change order to: (y, x, y, x)\n",
        "        target[\"img_size\"] = (new_h, new_w)\n",
        "        target[\"img_scale\"] = torch.tensor([1.0])\n",
        "        return image, target, image_id\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.image_ids)\n",
        "\n",
        "    def load_image_and_boxes(self, index):\n",
        "        \"\"\"\n",
        "        :return image: the image as a numpy array. The array is scaled to the [0,1] interval. Numpy array.\n",
        "        :return boxes: an array containing bounding boxes rows = [x0, y0, x0 + height, y0 + width]. List of lists.\n",
        "        \"\"\"\n",
        "        image_id = self.image_ids[index] # select image\n",
        "        image = cv2.imread(f'{paths.TRAIN_IMAGES_FOLDER}{image_id}.jpg', cv2.IMREAD_COLOR) # read image from path\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32) # convert to RGB \n",
        "        records = self.df[self.df['image_id'] == image_id] # select all rows corresponding to the image\n",
        "        boxes = records[['x0', 'y0', 'w', 'h']].values # get bounding box information\n",
        "        boxes[:, 2] = boxes[:, 0] + boxes[:, 2] # x0 + Δx (or also  x0 + height), pascal_voc format\n",
        "        boxes[:, 3] = boxes[:, 1] + boxes[:, 3] # y0 + Δy (or also  y0 + width), pascal_voc format\n",
        "        boxes = boxes.tolist() # convert to list\n",
        "        return image, boxes\n",
        "    \n",
        "    def get_labels(self, index):\n",
        "        image_id = self.image_ids[index]\n",
        "        labels = self.df[self.df['image_id'] == image_id][\"label\"].values.tolist()\n",
        "        labels = torch.tensor(labels)\n",
        "        return labels"
      ],
      "metadata": {
        "id": "vipb5BtFlnqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare dataloaders"
      ],
      "metadata": {
        "id": "oGj0x6e2lukL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "\n",
        "def prepare_loaders(fold, df):\n",
        "    \"\"\"\n",
        "    Splits data into Train and Validation sets depending on the current fold. Creates PyTorch\n",
        "    datasets from the splits. Creates DataLoaders from Datasets.\n",
        "    :param fold: current fold (int).\n",
        "    :param df: train dataframe (pandas dataframe).\n",
        "    :return train_loader, valid_loader: dataloaders for each stage.\n",
        "    \"\"\"\n",
        "    # === Select data for Train and Validation ===\n",
        "    train_df = df.query(\"fold!=@fold\").reset_index(drop=True) # Select all rows not from validation fold\n",
        "    valid_df = df.query(\"fold==@fold\").reset_index(drop=True) # Select all rows from validation fold\n",
        "    \n",
        "    # === Mini sample for debugging purposes ===\n",
        "    if config.DEBUG:\n",
        "        train_df = train_df.head(32*5).query(\"empty==0\")\n",
        "        valid_df = valid_df.head(32*3).query(\"empty==0\")\n",
        "    \n",
        "    # === Build Datasets ===\n",
        "    train_dataset = CustomDataset(train_df, transforms=get_train_transforms())\n",
        "    valid_dataset = CustomDataset(valid_df, transforms=get_valid_transforms())\n",
        "    \n",
        "    # === Create DataLoaders for Train and Validation ===\n",
        "    train_loader = DataLoader(train_dataset, \n",
        "                              batch_size=config.BATCH_SIZE_TRAIN if not config.DEBUG else 20, \n",
        "                              num_workers=config.NUM_WORKERS,\n",
        "                              sampler=RandomSampler(train_dataset),\n",
        "                              pin_memory=False, drop_last=False, collate_fn=collate_fn)\n",
        "    valid_loader = DataLoader(valid_dataset,\n",
        "                              batch_size=config.BATCH_SIZE_VALID if not config.DEBUG else 20, \n",
        "                              num_workers=config.NUM_WORKERS,\n",
        "                              sampler=SequentialSampler(valid_dataset),\n",
        "                              shuffle=False, pin_memory=True, collate_fn=collate_fn)\n",
        "    \n",
        "    return train_loader, valid_loader\n",
        "\n",
        "\n",
        "train_loader, valid_loader = prepare_loaders(fold=0, df=df)"
      ],
      "metadata": {
        "id": "Vzal03pUluTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scheduler"
      ],
      "metadata": {
        "id": "Xsyf3qitl9AY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_scheduler(optimizer):\n",
        "    if config.SCHEDULER == 'CosineAnnealingLR':\n",
        "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=config.T_MAX, \n",
        "                                                   eta_min=config.MIN_LR)\n",
        "    elif config.SCHEDULER == 'CosineAnnealingWarmRestarts':\n",
        "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=config.T_0, \n",
        "                                                             eta_min=config.MIN_LR)\n",
        "    elif config.SCHEDULER == 'ReduceLROnPlateau':\n",
        "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,\n",
        "                                                   mode='min',\n",
        "                                                   factor=0.1,\n",
        "                                                   patience=7,\n",
        "                                                   threshold=0.0001,\n",
        "                                                   min_lr=config.MIN_LR,)\n",
        "    elif config.SCHEDULER == 'ExponentialLR':\n",
        "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.85)\n",
        "    elif config.SCHEDULER == None:\n",
        "        return None\n",
        "        \n",
        "    return scheduler"
      ],
      "metadata": {
        "id": "lp7-3lHTl8xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "6WBBo3cVmIT9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create training Model"
      ],
      "metadata": {
        "id": "4vtrwEJnmMoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from effdet.config.model_config import efficientdet_model_param_dict\n",
        "from effdet import get_efficientdet_config, EfficientDet, DetBenchTrain, DetBenchPredict\n",
        "from effdet.efficientdet import HeadNet\n",
        "from effdet.config.model_config import efficientdet_model_param_dict\n",
        "\n",
        "def create_model(num_classes=config.NUM_CLASSES, image_size=512,\n",
        "                 architecture=\"tf_efficientnetv2_s\", verbose=False):\n",
        "    \n",
        "    efficientdet_model_param_dict['tf_efficientnetv2_s'] = dict(\n",
        "        name='tf_efficientnetv2_s',\n",
        "        backbone_name='tf_efficientnetv2_s',\n",
        "        backbone_args=dict(drop_path_rate=0.2),\n",
        "        num_classes=num_classes,\n",
        "        url='')\n",
        "    \n",
        "    cfg = get_efficientdet_config(architecture)\n",
        "    cfg.update({'num_classes': num_classes})\n",
        "    cfg.update({'image_size': (image_size, image_size)})\n",
        "    \n",
        "    if verbose:\n",
        "        pprint(cfg)\n",
        "\n",
        "    net = EfficientDet(cfg, pretrained_backbone=True)\n",
        "    net.class_net = HeadNet(\n",
        "        cfg,\n",
        "        num_outputs=cfg.num_classes,\n",
        "    )\n",
        "    return DetBenchTrain(net, cfg)\n",
        "\n",
        "\n",
        "def load_model(model_weights_path, model):\n",
        "    \"\"\"\n",
        "    Load model weights.\n",
        "    \"\"\"\n",
        "    model.load_state_dict(torch.load(model_weights_path))\n",
        "    model.eval()\n",
        "    return model"
      ],
      "metadata": {
        "id": "f5jHZOLfmMPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Average Meter : Track metrics and loss"
      ],
      "metadata": {
        "id": "nMJVuebgmbLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        \"\"\"Initializes an instance by reseting its values\"\"\"\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Resets all values to zero\"\"\"\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        \"\"\"\n",
        "        Tracks values, count, sum and average.\n",
        "        :param val: usually the loss function value.\n",
        "        :param n: usually the number of samples.\n",
        "        \"\"\"\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "metadata": {
        "id": "po1gWiEzmnN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Function : 1 epoch"
      ],
      "metadata": {
        "id": "Stabp9i_mhc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
        "    model.train() # Set model in training mode\n",
        "    loss_meter = AverageMeter() # Create instance\n",
        "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Train ') # Progress bar\n",
        "    for step, (images, targets, image_ids) in pbar:\n",
        "        # === Collate ===\n",
        "        images = torch.stack(images).to(device).float() # Get images (batch_size, 3, RESOLUTION, RESOLUTION)\n",
        "        batch_size = images.shape[0] # Get batch size\n",
        "        boxes = [target['boxes'].to(device).float() for target in targets] # Get bounding boxes\n",
        "        labels = [target['labels'].to(device).float() for target in targets] # Get labels (tuple with strings)\n",
        "        img_size = torch.tensor([target[\"img_size\"] for target in targets]).to(device).float()\n",
        "        img_scale = torch.tensor([target[\"img_scale\"] for target in targets]).to(device).float()\n",
        "        annotations = {\n",
        "            \"bbox\": boxes,\n",
        "            \"cls\": labels,\n",
        "            \"img_size\": img_size,\n",
        "            \"img_scale\": img_scale\n",
        "        }\n",
        "        optimizer.zero_grad() # Zero out gradients\n",
        "        loss = model(images, annotations) # Forward pass\n",
        "        loss = loss[\"loss\"]\n",
        "        loss.backward() # Back propagation\n",
        "        # Since the reduction type of the loss is \"mean\" we multiply by batch_size\n",
        "        loss_meter.update(loss.detach().item(), batch_size) # Update loss\n",
        "        optimizer.step() # Update params\n",
        "        scheduler.step() # Update learning rate\n",
        "        \n",
        "        # === Evaluate model ===\n",
        "        \n",
        "        mem = torch.cuda.memory_reserved() / 1e9 if torch.cuda.is_available() else 0 # Track memory\n",
        "        current_lr = optimizer.param_groups[0]['lr'] # Get current Learning Rate\n",
        "        pbar.set_postfix(train_loss=f'{loss_meter.avg:0.4f}',\n",
        "                         lr=f'{current_lr:0.5f}',\n",
        "                         gpu_mem=f'{mem:0.2f} GB')\n",
        "    # === Release memory ===\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    \n",
        "    return loss_meter"
      ],
      "metadata": {
        "id": "CR1qqLbemoLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validation Function : 1 epoch"
      ],
      "metadata": {
        "id": "sdBulxBxmvr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def valid_one_epoch(model, dataloader, device, epoch):\n",
        "    model.eval() # Set model in evaluation mode\n",
        "    loss_meter = AverageMeter() # Create instance\n",
        "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Valid ') # Progress bar\n",
        "    for step, (images, targets, image_ids) in pbar:  \n",
        "        # === Collate ===\n",
        "        images = torch.stack(images).to(device).float() # Get images\n",
        "        batch_size = images.shape[0] # Get batch size\n",
        "        boxes = [target['boxes'].to(device).float() for target in targets] # Get boxes\n",
        "        labels = [target['labels'].to(device).float() for target in targets] # Get labels\n",
        "        img_size = torch.tensor([target[\"img_size\"] for target in targets]).to(device).float()\n",
        "        img_scale = torch.tensor([target[\"img_scale\"] for target in targets]).to(device).float()\n",
        "        \n",
        "        annotations = {\n",
        "            \"bbox\": boxes,\n",
        "            \"cls\": labels,\n",
        "            \"img_size\": img_size,\n",
        "            \"img_scale\": img_scale\n",
        "        }\n",
        "        loss = model(images, annotations) # Forward pass\n",
        "        loss = loss[\"loss\"]\n",
        "        loss_meter.update(loss.detach().item(), batch_size) # Update loss\n",
        "        # === Evaluate model ===\n",
        "        \n",
        "        mem = torch.cuda.memory_reserved() / 1e9 if torch.cuda.is_available() else 0 # Track memory\n",
        "        current_lr = optimizer.param_groups[0]['lr'] # Get current learning rate\n",
        "        pbar.set_postfix(valid_loss=f'{loss_meter.avg:0.4f}',\n",
        "                         lr=f'{current_lr:0.5f}',\n",
        "                         gpu_memory=f'{mem:0.2f} GB')\n",
        "    # === Release memory ===\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    \n",
        "    return loss_meter"
      ],
      "metadata": {
        "id": "o1_cGVBQmumP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Loop"
      ],
      "metadata": {
        "id": "nHuXHHAZm9YG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(model, optimizer, scheduler, device, num_epochs):\n",
        "    f = open(f\"/kaggle/working/logs/logs.txt\", \"w+\") # Create log file\n",
        "    \n",
        "    if torch.cuda.is_available(): # Check if GPU is available\n",
        "        print(\"Cuda: {}\\n\".format(torch.cuda.get_device_name()))\n",
        "    \n",
        "    start = time.time() # Track execution time\n",
        "    best_model_weights = copy.deepcopy(model.state_dict())\n",
        "    epochs = config.EPOCHS\n",
        "    best_loss = 1e10\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        print(f'Epoch {epoch}/{num_epochs}', end='')\n",
        "        loss_meter_train = train_one_epoch(model, optimizer, scheduler, \n",
        "                                           dataloader=train_loader, \n",
        "                                           device=config.DEVICE, epoch=epoch)\n",
        "        \n",
        "        loss_meter_valid = valid_one_epoch(model, valid_loader, \n",
        "                                           device=config.DEVICE, \n",
        "                                           epoch=epoch)\n",
        "        \n",
        "        duration = str(timedelta(seconds=time.time() - start))[:7]\n",
        "        # === Print to log file ===\n",
        "        with open(f\"logs/logs.txt\", 'a+') as f:\n",
        "            print('{} | Epoch: {}/{} | Train Loss: {:.4} '. \\\n",
        "            format(duration, epoch + 1, epochs, loss_meter_train.avg), file=f)\n",
        "            print('{} | Epoch: {}/{} | Valid Loss: {:.4}'. \\\n",
        "            format(duration, epoch + 1, epochs, loss_meter_valid.avg), file=f)\n",
        "            print(\"\\n\" + \"-\"*100 + \"\\n\", file=f)\n",
        "        \n",
        "        # === Save model if there is an improvement ===\n",
        "        if loss_meter_valid.avg < best_loss:\n",
        "            best_loss = loss_meter_valid.avg\n",
        "            best_epoch = epoch\n",
        "            best_model_weights = copy.deepcopy(model.state_dict())\n",
        "            PATH = f\"/kaggle/working/saved_models/best_epoch-{fold:02d}.bin\"\n",
        "            torch.save(model.state_dict(), PATH)\n",
        "            print(f\"Model Saved | Best Epoch {best_epoch} | Best Loss {round(best_loss,2)} {sr_}\")\n",
        "            \n",
        "        last_model_wts = copy.deepcopy(model.state_dict())\n",
        "        PATH = f\"last_epoch-{fold:02d}.bin\"\n",
        "        torch.save(model.state_dict(), PATH)\n",
        "        print(); print()\n",
        "    \n",
        "    end = time.time()\n",
        "    time_elapsed = end - start\n",
        "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "PiQYZ2K0m8sR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "fIV2JRdYnAed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for fold in range(1):\n",
        "    print(f'================= Fold: {1} =================')\n",
        "    train_loader, valid_loader = prepare_loaders(fold=fold, df=df)\n",
        "    model = create_model()\n",
        "    model.to(config.DEVICE)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=config.LR, weight_decay=config.WEIGHT_DECAY)\n",
        "    scheduler = fetch_scheduler(optimizer)\n",
        "    model = train_loop(model, optimizer, scheduler,\n",
        "                       device=config.DEVICE,\n",
        "                       num_epochs=config.EPOCHS)"
      ],
      "metadata": {
        "id": "yIrIMtXBnAIE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}